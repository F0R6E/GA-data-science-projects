{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<a name=\"introduction\"></a>\n",
    "\n",
    "This week I am going to do a fun project, I was going to webscrape bunch of movie websites like iMDB, rotten tomato and from there I will try to scrape a lot of info about these movies. Some I will use for visualization and most others will be used to create a machine learning model which would be able to predict a movie score. So, let's get started. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "- [Introduction](#introduction)\n",
    "- [Import necessary modules](#modules)\n",
    "- [Imdb_webscraping_part#1](#imdb1)\n",
    "- [Imdb_webscraping_part#2](#imdb2)\n",
    "- [Rotten tomato webscraping](#Rotten tomato webscraping)\n",
    "- [Cleaning All datasets(This is the starting point of this project after collecting all the data)](#cleaning_data_sets)\n",
    "- [Visualization](#visualization)\n",
    "- [Feature Engineering](#feature_engineering)\n",
    "- [Train-test split](#train_test_split)\n",
    "- [Creating models](#creating_models)\n",
    "- [Result metrics](#result_metrics)\n",
    "- [Feature Importance](#feature_importance)\n",
    "- [ROC/AUC curve](#roc_auc_curve)\n",
    "- [Wrapping Up](#wrapping_up)\n",
    "- [Next](#next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all the necessary modules\n",
    "<a name=\"#modules\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "pd.set_option('display.max_columns', 500) ## to see all the columns,\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imdb webscraping part #1\n",
    "<a name=\"imdb1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 269 ms, total: 15.5 s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Creating couple of empty list that will be used to create the dataframe. \n",
    "title_id = []\n",
    "title = []\n",
    "runtime =[]\n",
    "genre = []\n",
    "certificate = []\n",
    "imdb_rating = []\n",
    "gross = []\n",
    "year = []\n",
    "votes = []\n",
    "director_actor=[]\n",
    "metascore=[]\n",
    "## Looping through each page of the IMDB website which consists of 50\n",
    "##movies in each page, picking movies only with more than 1000 votes \n",
    "#and a rating higher than 9 and lower than 5\n",
    "\n",
    "## a is doing 30 iterations to get 1500 movies\n",
    "for a in range(30): \n",
    "    ## b is doing 2 iterations to switch r value\n",
    "    for b in range(2): \n",
    "        \n",
    "        # r with rating above 8\n",
    "        r = requests.get(\"http://www.imdb.com/search/title?num_votes=1000,&title_type=feature,tv_movie,documentary,\\\n",
    "                          short&user_rating=8.0,&page=\"+str(a)+\"&ref_=adv_nxt\")\n",
    "       \n",
    "        ## altering the value of r, in order to scrape movies with rating lower than 5.\n",
    "        if b == 1:\n",
    "         \n",
    "            # r with rating below 5\n",
    "            r = requests.get(\"http://www.imdb.com/search/title?num_votes=1000,&title_type=feature,tv_movie,documentary,\\\n",
    "                              short&user_rating=,5.0&page=\"+str(a)+\"&ref_=adv_nxt\")\n",
    "       \n",
    "        ## use BeautifulSoup based on either r\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "        \n",
    "        for i in soup.findAll(class_='lister-item-content'):\n",
    "            \n",
    "            # Getting title_id\n",
    "            title_id.append(re.findall(r'tt.+\\d', str(i.find(\"a\"))))\n",
    "            \n",
    "            # Getting title\n",
    "            title.append(i.find('a').text.strip())\n",
    "            \n",
    "            # Gerring genre\n",
    "            try:\n",
    "                genre.append(i.find('span', class_ = \"genre\").text.strip())\n",
    "            except:\n",
    "                genre.append(None)\n",
    "            \n",
    "            # Getting runtime\n",
    "            try:\n",
    "                # runtime.append(re.findall(r'\\d+', i.find('span', class_ = \"runtime\").text)[0])\n",
    "                runtime.append(re.findall(r'\\d+', i.find('span', class_ = \"runtime\").text))\n",
    "            except:\n",
    "                runtime.append(None)\n",
    "            \n",
    "            # Getting certificate    \n",
    "            try:\n",
    "                certificate.append(i.find(\"span\", class_ =\"certificate\").text)\n",
    "            except:\n",
    "                certificate.append(None)\n",
    "            \n",
    "            # Getting imdb_rating\n",
    "            imdb_rating.append(float(i.find(\"strong\").text))\n",
    "            \n",
    "            # Getting year\n",
    "            year.append(i.find(\"span\", class_=\"lister-item-year text-muted unbold\").text)\n",
    "            \n",
    "            # Getting votes\n",
    "            votes.append((i.find(\"span\", attrs={\"name\":\"nv\"}).text).replace(\",\",\"\"))\n",
    "            \n",
    "            # Getting gross\n",
    "            try:\n",
    "                #gross.append(i.find(\"span\", attrs={\"name\":\"nv\"}).find_next_sibling(\"span\", attrs={\"name\":\"nv\"}).get_text())\n",
    "                gross.append(re.findall(r'\\d.+\\d', i.find(\"span\", attrs={\"name\":\"nv\"}).find_next_sibling(\"span\", \\\n",
    "                attrs={\"name\":\"nv\"}).get_text()))\n",
    "            except:\n",
    "                gross.append(None)\n",
    "            \n",
    "            ## Getting director and actors\n",
    "            try:\n",
    "                director_actor.append(i.find(\"p\", class_=\"text-muted\").find_next_sibling(\"p\", class_=\"\").text.strip())\n",
    "            except:\n",
    "                director.append(None)\n",
    "            \n",
    "            ## Getting metascore\n",
    "            try:\n",
    "                metascore.append(int(i.find(\"span\",  class_=\"metascore favorable\").text.strip()))\n",
    "            except:\n",
    "                metascore.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "## checking the length of each features\n",
    "print (len(title_id))\n",
    "print (len(title))\n",
    "print (len(runtime))\n",
    "print (len(genre))\n",
    "print (len(certificate))\n",
    "print (len(imdb_rating))\n",
    "print (len(gross))  ## there seems to be a problem with the gross, will look into that. \n",
    "print (len(year))\n",
    "print (len(votes))\n",
    "print (len(director_actor))\n",
    "print (len(metascore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'Bohemian Rhapsody',\n",
       " 'The Favourite',\n",
       " 'Green Book',\n",
       " 'Roma',\n",
       " 'A Star Is Born',\n",
       " 'Avengers: Infinity War',\n",
       " 'Dragon Ball Super: Broly',\n",
       " 'How to Train Your Dragon: The Hidden World',\n",
       " 'The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Dark Knight',\n",
       " 'Pulp Fiction',\n",
       " 'Gone Girl',\n",
       " 'Three Billboards Outside Ebbing, Missouri',\n",
       " 'The Wolf of Wall Street',\n",
       " 'The Revenant',\n",
       " 'Interstellar',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Inception',\n",
       " 'Guardians of the Galaxy',\n",
       " 'Blade Runner 2049',\n",
       " 'The Intouchables',\n",
       " 'The Big Lebowski',\n",
       " 'Uri: The Surgical Strike',\n",
       " 'Andhadhun',\n",
       " 'Room',\n",
       " 'Mad Max: Fury Road',\n",
       " 'The Dark Knight Rises',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Shoplifters',\n",
       " 'Wonder',\n",
       " 'Petta',\n",
       " 'The Avengers',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'The Departed',\n",
       " 'Harry Potter and the Deathly Hallows: Part 2',\n",
       " 'Inglourious Basterds',\n",
       " 'The Green Mile',\n",
       " 'Monty Python and the Holy Grail',\n",
       " 'The Silence of the Lambs',\n",
       " 'Deadpool',\n",
       " 'K.G.F: Chapter 1',\n",
       " \"Pan's Labyrinth\",\n",
       " 'Goodfellas',\n",
       " 'Se7en',\n",
       " 'La La Land',\n",
       " 'The Matrix',\n",
       " 'Logan',\n",
       " 'Holmes & Watson',\n",
       " 'Gojira: hoshi wo kû mono',\n",
       " 'How It Ends',\n",
       " 'What Still Remains',\n",
       " 'Escape Room',\n",
       " 'The Little Mermaid',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Fifty Shades Freed',\n",
       " 'The Happening',\n",
       " 'The Possession of Hannah Grace',\n",
       " '2036 Origin Unknown',\n",
       " 'Knock Knock',\n",
       " 'A Wrinkle in Time',\n",
       " 'SuperFly',\n",
       " '10x10',\n",
       " 'Escape Plan 2: Hades',\n",
       " 'Sex and the City 2',\n",
       " 'Slender Man',\n",
       " 'The Room',\n",
       " 'Fifty Shades Darker',\n",
       " 'Left Behind',\n",
       " 'Gotti',\n",
       " 'Thugs of Hindostan',\n",
       " 'The Titan',\n",
       " 'Jason X',\n",
       " '211',\n",
       " 'The Last Airbender',\n",
       " 'Malevolent',\n",
       " 'Fantastic Four',\n",
       " 'Scooby-Doo',\n",
       " 'Movie 43',\n",
       " 'You Get Me',\n",
       " 'Escape Room',\n",
       " 'Dark Crimes',\n",
       " 'Siberia',\n",
       " 'The Open House',\n",
       " 'The Ridiculous 6',\n",
       " 'Da hong zha',\n",
       " 'Batman & Robin',\n",
       " 'Perfect',\n",
       " 'Patient Zero',\n",
       " 'Samson',\n",
       " 'Did You Hear About the Morgans?',\n",
       " 'Reprisal',\n",
       " 'Showgirls',\n",
       " 'Jason Goes to Hell: The Final Friday',\n",
       " 'After Earth',\n",
       " 'Striptease',\n",
       " 'The Twilight Saga: Eclipse',\n",
       " 'My Teacher, My Obsession',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix title_id since its picking up some extra characters we do not want. \n",
    "a = []\n",
    "for i in title_id:\n",
    "    for j in i:\n",
    "        a.append(j.split(\"/\")[0])\n",
    "title_id = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_list = [title_id, title, runtime, genre, certificate, imdb_rating, gross, year, votes, director_actor, metascore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header =[\"title_id\", \"title\", \"runtime\", \"genre\", \"certificate\", \"imdb_rating\", \"gross\", \"year\", \"votes\", \"director_actor\", \"metascore\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The code above ran in AWS and once the web scrapig was completed, the data was stored as a csv file in EC2. \n",
    "df.to_csv('imdb_1.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"imdb2\"></a>\n",
    "#### Imdb webscarping part #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.stdout = open('/dev/stdout', 'w') ## this is just for me to print out \"w\" in the termin and make sure that My code is working\n",
    "\n",
    "user_review =[]\n",
    "critic_review = []\n",
    "writer = []\n",
    "language = []\n",
    "country = []\n",
    "budget = []\n",
    "gross_1 = []\n",
    "opening_week=[]\n",
    "oscar_win = []\n",
    "oscar_nom = []\n",
    "other_win = []\n",
    "other_nom = []\n",
    "count = 0\n",
    "for i in title_id:\n",
    "    \n",
    "    sys.stdout.write(i + '\\n')\n",
    "    \n",
    "    r = requests.get(\"http://www.imdb.com/title/\"+str(i)+\"/?ref_=nv_sr_1\")\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    \n",
    "    # Getting User_review_no\n",
    "    try:\n",
    "        user_review.append(re.findall(r'.+\\d', soup.find('span', attrs={'itemprop':\"reviewCount\"}).text))\n",
    "    except:\n",
    "        user_review.append(None)\n",
    "    # Getting Critic_no\n",
    "    try:\n",
    "        critic_review.append(re.findall(r'.+\\d',soup.find('span', attrs={'itemprop':\"reviewCount\"}).find_next_sibling().text))\n",
    "    except:\n",
    "        critic_review.append(None)\n",
    "        \n",
    "    \"\"\"try:\n",
    "        won.append(soup.find(\"span\", itemprop=\"awards\").text.strip())\n",
    "    except:\n",
    "        won.append(None)\"\"\"\n",
    "    # Getting Writer\n",
    "    try:\n",
    "        writer.append(soup.find('span', attrs={'itemprop':\"creator\"}).text)\n",
    "    except:\n",
    "        writer.append(None)\n",
    "    \"\"\"for i in soup.find_all('h4',class_ = \"inline\"):\n",
    "        if i.text.strip() == \"Writers:\" or i.text.strip() ==\"Writer\":\n",
    "            writer.append(i.find_next().text.strip())\"\"\"\n",
    "    \n",
    "    # Getting Language\n",
    "    a = 0\n",
    "    try:\n",
    "        for i in soup.find_all(\"h4\", class_ = 'inline'):\n",
    "            if i.text.strip() == \"Language:\":\n",
    "                a = i.find_next().text\n",
    "                #language.append(i.find_next().text)\n",
    "    except:\n",
    "        a = None\n",
    "    language.append(a)\n",
    "        \n",
    "    # Getting Country\n",
    "    a = 0\n",
    "    try:\n",
    "        for i in soup.find_all('h4',class_ = \"inline\"):\n",
    "            if i.text.strip() == \"Country:\":\n",
    "                a = i.find_next().text.strip()\n",
    "                #country.append(i.find_next().text.strip())\n",
    "    except:\n",
    "        a = None\n",
    "    country.append(a)\n",
    "            \n",
    "    # Getting Budget\n",
    "    a = 0\n",
    "    try:\n",
    "        for i in soup.find_all(\"h4\", class_ = \"inline\"):\n",
    "            if i.text.strip() == \"Budget:\":\n",
    "                a = (i.next_sibling.strip()).replace(\",\",\"\")\n",
    "               # budget.append((i.next_sibling.strip()).replace(\",\",\"\"))\n",
    "    except:\n",
    "        a = None\n",
    "    budget.append(a)\n",
    "            \n",
    "    # Getting Gross\n",
    "    a = 0\n",
    "    try:\n",
    "        for i in soup.find_all(\"h4\", class_ = \"inline\"):\n",
    "            if i.text.strip() == \"Gross:\":    \n",
    "                a = (i.next_sibling.strip()).replace(\",\",\"\")\n",
    "                #gross_1.append((i.next_sibling.strip()).replace(\",\",\"\"))\n",
    "    except:\n",
    "        a = None\n",
    "    gross_1.append(a)\n",
    "        \n",
    "    # Getting Opening Weekend\n",
    "    a = 0\n",
    "    try:\n",
    "        for i in soup.find_all(\"h4\", class_ = \"inline\"):\n",
    "            if i.text.strip() == \"Opening Weekend:\":\n",
    "                a = (i.next_sibling.strip()).replace(\",\",\"\")\n",
    "                #opening_week.append((i.next_sibling.strip()).replace(\",\",\"\"))\n",
    "    except:\n",
    "        a = None\n",
    "    opening_week.append(a)\n",
    "    \n",
    "    \n",
    "    # Getting Oscar, Oscar_nomination, Other_awards, Other_nomminations\n",
    "    # getting oscar\n",
    "    while soup.find_all(\"span\", attrs={\"itemprop\":\"awards\"}):\n",
    "        for i in soup.find_all(\"span\", attrs={\"itemprop\":\"awards\"}):\n",
    "            if \"Won\" in i.text and (\"Oscar.\" in i.text or \"Oscars.\" in i.text):\n",
    "                oscar_win.append(re.findall(r'\\d+', i.text.strip(\"\")))\n",
    "                break\n",
    "            else:\n",
    "                oscar_win.append(None)\n",
    "                break\n",
    "        break\n",
    "    else:\n",
    "        oscar_win.append(None)\n",
    "        \n",
    "    # find nominations for oscar\n",
    "    while soup.find_all(\"span\", attrs={\"itemprop\":\"awards\"}):\n",
    "        for i in soup.find_all(\"span\", attrs={\"itemprop\":\"awards\"}):\n",
    "            if \"Nominated\" in i.text and (\"Oscar.\" in i.text or \"Oscars.\" in i.text):\n",
    "                oscar_nom.append(re.findall(r'\\d+', i.text.strip(\"\")))\n",
    "                break\n",
    "            else:\n",
    "                oscar_nom.append(None)\n",
    "                break\n",
    "        break\n",
    "    else:\n",
    "        oscar_nom.append(None)\n",
    "    \n",
    "    # Getting other wins\n",
    "    try:\n",
    "        for i in soup.find_all(\"span\", attrs={\"itemprop\":\"awards\"}):\n",
    "            #print i.text\n",
    "            if (\"wins\" in i.text or \"win\" in i.text) and (\"nominations\" in i.text or \"nomination.\" in i.text):\n",
    "                a = re.findall(r'\\d+', i.text.strip(\"\"))[0]\n",
    "            elif (\"wins\" in i.text or \"win\" in i.text) and (\"nominations\" not in i.text or \"nomination.\" not in i.text):\n",
    "                a = re.findall(r'\\d+', i.text.strip(\"\"))[0]\n",
    "            elif (\"wins\" not in i.text or \"win\" not in i.text) and (\"nominations\" in i.text or \"nomination.\" in i.text):\n",
    "                a = None\n",
    "    except:\n",
    "        a = None\n",
    "    other_win.append(a)\n",
    "        \n",
    "        \n",
    "    # Getting other nominations\n",
    "    try:\n",
    "        for i in soup.find_all(\"span\", attrs={\"itemprop\":\"awards\"}):\n",
    "            #print i.text\n",
    "            if (\"wins\" in i.text or \"win\" in i.text) and (\"nominations\" in i.text or \"nomination.\" in i.text):\n",
    "                #other_nom.append(re.findall(r'\\d+', i.text.strip(\"\"))[1])\n",
    "                a = re.findall(r'\\d+', i.text.strip(\"\"))[1]\n",
    "            elif (\"wins\" in i.text or \"win\" in i.text) and (\"nominations\" not in i.text or \"nomination.\" not in i.text):\n",
    "                a = None\n",
    "            elif (\"wins\" not in i.text or \"win\" not in i.text) and (\"nominations\" in i.text or \"nomination.\" in i.text):\n",
    "                a = re.findall(r'\\d+', i.text.strip(\"\"))[0]\n",
    "    except:\n",
    "        a = None\n",
    "    other_nom.append(a)\n",
    "    count += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checking the length of each features\n",
    "\n",
    "print (len(user_review))\n",
    "print (len(critic_review))\n",
    "print (len(writer))\n",
    "print (len(language))\n",
    "print (len(country))\n",
    "print (len(budget))\n",
    "print (len(gross_1))\n",
    "print (len(opening_week))\n",
    "print (len(oscar_win))\n",
    "print (len(oscar_nom))\n",
    "print (len(other_win))\n",
    "print (len(other_nom))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## creating a second list with all the scraped features\n",
    "data_list_2 = [user_review, critic_review, writer, language, country, budget, gross_1, opening_week, oscar_win, oscar_nom, other_win, other_nom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.DataFrame(data_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "header2 = [\"user_review\", \"critic_review\", \"writer\", \"language\", \"country\", \"budget\", \"gross_1\", \"opening_week\", \"oscar_win\", \"oscar_nom\", \"other_win\", \"other_nom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.columns = header2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The code above ran in AWS and once the scrapig was completed, the scraped data stored as a csv file in EC2. \n",
    "df2.to_csv('imdb_2.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting all the titles in order to run through rotten tomato. \n",
    "title = df1[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## making necessary changes in order to fit the rotten tomato urls. \n",
    "title = title.apply(lambda x:x.replace(\" \", \"_\"))\n",
    "title = title.apply(lambda x:x.replace(\".\", \"\"))\n",
    "title = title.apply(lambda x:x.replace(\":\", \"\"))\n",
    "title = title.apply(lambda x:x.replace(\"-\", \"\"))\n",
    "title = title.apply(lambda x:x.replace(\",\", \"\"))\n",
    "title = title.apply(lambda x:x.replace(\"'\", \"\"))\n",
    "title = title.apply(lambda x:x.replace(\"__\", \"_\"))\n",
    "\n",
    "## changes that name of the spoted movies to fit the url. \n",
    "title = title.apply(lambda x:x.replace(\"Logan\", \"logan_2017\"))\n",
    "title = title.apply(lambda x:x.replace(\"Lion\", \"lion_2016\"))\n",
    "title = title.apply(lambda x:x.replace(\"Bahubali_The_Beginning\", \"Baahubali_The_Beginning\"))\n",
    "title = title.apply(lambda x:x.replace(\"Star_Wars_Episode_V__The_Empire_Strikes_Back\", \"empire_strikes_back\"))\n",
    "title = title.apply(lambda x:x.replace(\"Kavkazskaya_plennitsa_ili_Novye_priklyucheniya_Shurika\", \"kavkazskaya_plennitsa_ili_novye_priklyucheniya_shurika_kidnapping_caucassian_style\"))\n",
    "title = title.apply(lambda x:x.replace(\"Star_Wars_Episode_IV_A_New_Hope\", \"star_wars\"))\n",
    "title = title.apply(lambda x:x.replace(\"Tom_Petty_and_the_Heartbreakers_Runnin_Down_a_Dream\", \"runnin_down_a_dream_tom_petty_and_the_heartbreakers\"))\n",
    "title = title.apply(lambda x:x.replace(\"The_Incredibly_Strange_Creatures_Who_Stopped_Living_and_Became_MixedUp_Zombies!!?\", \"the_incredibly_strange_creatures\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotten_tomato webscraping\n",
    "<a name=\"Rotten tomato webscraping\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "\n",
    "rt_score = []\n",
    "rt_avg_rating = []\n",
    "rt_audience_score = []\n",
    "rt_user_rating = []\n",
    "rt_avg_aud_rating = []\n",
    "rt_fresh = []\n",
    "rt_rotten = []\n",
    "\n",
    "for i in title:\n",
    "    \n",
    "    sys.stdout.write(i + '\\n')\n",
    "    \n",
    "    r = requests.get(\"https://www.rottentomatoes.com/m/\"+str(i))\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    \n",
    "    # Getting tomato meter score.\n",
    "    a = 0\n",
    "    for i in soup.find_all(\"h3\", class_ =\"scoreTitle superPageFontColor\"):\n",
    "        if i.text.strip() == \"TOMATOMETER\":\n",
    "            try:\n",
    "                a = i.find_next(\"span\", class_=\"meter-value superPageFontColor\").text\n",
    "            except:\n",
    "                a = None\n",
    "    rt_score.append(a)\n",
    "    \n",
    "    # Getting average_rating from tomatometer \n",
    "    a = 0\n",
    "    for i in soup.find_all(\"div\", attrs= {\"id\":\"all-critics-numbers\"}):\n",
    "        try:\n",
    "            a = re.findall(r'./.\\d', i.text.strip())[0]\n",
    "        except:\n",
    "            a = None\n",
    "    rt_avg_rating.append(a)\n",
    "    \n",
    "    # Getting audience score meter score.\n",
    "    a = 0\n",
    "    for i in soup.find_all(\"h3\", class_ =\"scoreTitle superPageFontColor\"):\n",
    "        if i.text.strip() == \"AUDIENCE SCORE\":\n",
    "            try:\n",
    "                a = i.find_next(\"span\" ,class_ =\"superPageFontColor\").text\n",
    "            except:\n",
    "                a = None\n",
    "    rt_audience_score.append(a)\n",
    "    \n",
    "    # Getting user rating from Rotten Tomato\n",
    "    a = 0\n",
    "    for i in soup.find_all(\"span\" ,class_ =\"subtle superPageFontColor\"):\n",
    "        if i.text == \"User Ratings:\":\n",
    "            try:\n",
    "                a = i.next_sibling.strip()\n",
    "            except:\n",
    "                a = None\n",
    "    rt_user_rating.append(a)\n",
    "    \n",
    "    # Getting Average rating from Rotten Tomato(Audience score)\n",
    "    a = 0\n",
    "    for i in soup.find_all(\"span\" ,class_ =\"subtle superPageFontColor\"):\n",
    "        if i.text == \"Average Rating:\":\n",
    "            try:\n",
    "                a = i.next_sibling.strip()\n",
    "            except:\n",
    "                a = None\n",
    "    rt_avg_aud_rating.append(a)\n",
    "    \n",
    "    # finding fresh for all critic\n",
    "    a = 0\n",
    "    for i in soup.find_all(\"span\" ,class_ =\"subtle superPageFontColor audience-info\"):\n",
    "        if i.text.strip() == \"Fresh:\":\n",
    "            a = int(i.find_next().text)\n",
    "            break\n",
    "    rt_fresh.append(a)\n",
    "    \n",
    "    # finding rotten for all critic\n",
    "    a = 0\n",
    "    for i in soup.find_all(\"span\" ,class_ =\"subtle superPageFontColor audience-info\"):\n",
    "        if i.text.strip() == \"Rotten:\":\n",
    "            a = int(i.find_next().text)\n",
    "            break\n",
    "    rt_rotten.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating a third list with all the scraped features\n",
    "data_list_3 = [rt_score, rt_avg_rating, rt_audience_score, rt_user_rating, rt_avg_aud_rating, rt_fresh, rt_rotten ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in data_list_3:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df3 = pd.DataFrame(data_list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df3.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "header3 = [\"rt_score\", \"rt_avg_rating\", \"rt_audience_score\", \"rt_user_rating\", \"rt_avg_aud_rating\", \"rt_fresh\", \"rt_rotten\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.columns = header3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The code above ran in AWS and once the scrapig was completed, the scraped data stored as a csv file in EC2. \n",
    "df3.to_csv('rt.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## re-ran the code for meta score. \n",
    "mt_score = []\n",
    "\n",
    "for i in title_id:\n",
    "    r = requests.get(\"http://www.imdb.com/title/\"+str(i)+\"/?ref_=nv_sr_2\")\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    a = 0\n",
    "    try:\n",
    "        a = soup.find(\"a\", attrs={\"href\":\"criticreviews?ref_=tt_ov_rt\"}).text.strip()\n",
    "    except:\n",
    "        a =  None\n",
    "    print a\n",
    "    mt_score.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = [\"metascores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mt.to_csv(\"meta.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning all the datasets\n",
    "<a name =\"cleaning_data_sets\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This can be the socend part of this project, from here on, I dont have to worry web scraping and all \n",
    "## the scraped data was saved in a csv file and imported fresh with the following codes\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mProject-Netflix-Movie-Recommender.ipynb\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'imdb_1.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f0f52787e2fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## getting the scraped csv files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imdb_1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imdb_2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rt.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meta.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'imdb_1.csv' does not exist"
     ]
    }
   ],
   "source": [
    "## getting the scraped csv files. \n",
    "df1 = pd.read_csv('imdb_1.csv')\n",
    "df2 = pd.read_csv('imdb_2.csv')\n",
    "df3 = pd.read_csv('rt.csv')\n",
    "df4 = pd.read_csv('meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping the first columns of each datasets\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Assigning header for df4\n",
    "header = [\"metascores\"]\n",
    "df4.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>title</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genre</th>\n",
       "      <th>certificate</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>gross</th>\n",
       "      <th>year</th>\n",
       "      <th>votes</th>\n",
       "      <th>director_actor</th>\n",
       "      <th>metascore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt4912910</td>\n",
       "      <td>Mission: Impossible - Fallout</td>\n",
       "      <td>['147']</td>\n",
       "      <td>Action, Adventure, Thriller</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.4</td>\n",
       "      <td>['83.86']</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>47815</td>\n",
       "      <td>Director:\\nChristopher McQuarrie\\n| \\n    Star...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt4154756</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>['149']</td>\n",
       "      <td>Action, Adventure, Fantasy</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.7</td>\n",
       "      <td>['677.76']</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>417825</td>\n",
       "      <td>Directors:\\nAnthony Russo, \\nJoe Russo\\n| \\n  ...</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt3606756</td>\n",
       "      <td>Incredibles 2</td>\n",
       "      <td>['118']</td>\n",
       "      <td>Animation, Action, Adventure</td>\n",
       "      <td>PG</td>\n",
       "      <td>8.1</td>\n",
       "      <td>['577.02']</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>77932</td>\n",
       "      <td>Director:\\nBrad Bird\\n| \\n    Stars:\\nCraig T....</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt5463162</td>\n",
       "      <td>Deadpool 2</td>\n",
       "      <td>['119']</td>\n",
       "      <td>Action, Adventure, Comedy</td>\n",
       "      <td>R</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['317.81']</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>189429</td>\n",
       "      <td>Director:\\nDavid Leitch\\n| \\n    Stars:\\nRyan ...</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt5104604</td>\n",
       "      <td>Isle of Dogs</td>\n",
       "      <td>['101']</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['31.97']</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>58787</td>\n",
       "      <td>Director:\\nWes Anderson\\n| \\n    Stars:\\nBryan...</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title_id                          title  runtime  \\\n",
       "0  tt4912910  Mission: Impossible - Fallout  ['147']   \n",
       "1  tt4154756         Avengers: Infinity War  ['149']   \n",
       "2  tt3606756                  Incredibles 2  ['118']   \n",
       "3  tt5463162                     Deadpool 2  ['119']   \n",
       "4  tt5104604                   Isle of Dogs  ['101']   \n",
       "\n",
       "                          genre certificate  imdb_rating       gross    year  \\\n",
       "0   Action, Adventure, Thriller       PG-13          8.4   ['83.86']  (2018)   \n",
       "1    Action, Adventure, Fantasy       PG-13          8.7  ['677.76']  (2018)   \n",
       "2  Animation, Action, Adventure          PG          8.1  ['577.02']  (2018)   \n",
       "3     Action, Adventure, Comedy           R          8.0  ['317.81']  (2018)   \n",
       "4  Animation, Adventure, Comedy       PG-13          8.0   ['31.97']  (2018)   \n",
       "\n",
       "    votes                                     director_actor  metascore  \n",
       "0   47815  Director:\\nChristopher McQuarrie\\n| \\n    Star...       86.0  \n",
       "1  417825  Directors:\\nAnthony Russo, \\nJoe Russo\\n| \\n  ...       68.0  \n",
       "2   77932  Director:\\nBrad Bird\\n| \\n    Stars:\\nCraig T....       80.0  \n",
       "3  189429  Director:\\nDavid Leitch\\n| \\n    Stars:\\nRyan ...       66.0  \n",
       "4   58787  Director:\\nWes Anderson\\n| \\n    Stars:\\nBryan...       82.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Adding all the colummns together. \n",
    "df = pd.concat([df1, df2, df3, df4], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.replace('N/A',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping duplicates \n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## dropping gross column, since I already have another column for gross with less NaN values\n",
    "df.drop(\"gross\",inplace = True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning runtime. \n",
    "<a name = \"cleaning_runtime\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"runtime\"] = df['runtime'].str.extract(r'(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[\"runtime\"] = df[\"runtime\"].apply(lambda x: None if x is None else int(re.findall(r'\\d+',i)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.runtime.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill the 4 missing values with the average. \n",
    "df.runtime.fillna(106, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.runtime.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning Award rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.oscar_win = df.oscar_win.str.extract(r'(\\d+)')\n",
    "df.oscar_nom = df.oscar_nom.str.extract(r'(\\d+)')\n",
    "df.oscar_win.fillna(0, inplace=True)\n",
    "df.oscar_nom.fillna(0, inplace=True)\n",
    "df.other_win.fillna(0, inplace=True)\n",
    "df.other_nom.fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_win = []\n",
    "for i in df.other_win:\n",
    "    a = 0\n",
    "    try:\n",
    "        a = int(i)\n",
    "    except:\n",
    "        a = 0\n",
    "    other_win.append(a)\n",
    "    \n",
    "df.other_win = other_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_nom = []\n",
    "for i in df.other_nom:\n",
    "    a = 0\n",
    "    try:\n",
    "        a = int(i)\n",
    "    except:\n",
    "        a = 0\n",
    "    other_nom.append(a)\n",
    "    \n",
    "df.other_nom = other_nom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning Genre and Creating columns for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.genre.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.genre.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filled the 3 missing genre rows with \"Drama\"\n",
    "df.genre.fillna(\"Drama\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a unique list for genre.\n",
    "unique_genre = []\n",
    "for i in df.genre:\n",
    "    a = i.split(\",\")\n",
    "    for b in a:\n",
    "        if b.strip() not in unique_genre:\n",
    "            unique_genre.append(b.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create a cleaned list of lists where each list is a row from each row of the dataFrame. \n",
    "cleaned_genre = []\n",
    "for i in df.genre:\n",
    "    a = i.split(\",\")\n",
    "    c =[]\n",
    "    for b in a:\n",
    "        c.append(b.strip())\n",
    "    cleaned_genre.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating new columns in the dataFrame and based on unique genre list, pluging in 1 or 0\n",
    "for i in unique_genre:\n",
    "    df[i] = [1 if i in x else 0 for x in cleaned_genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping genre and opening_week columns \n",
    "df.drop(\"genre\", axis=1, inplace=True)\n",
    "df.drop(\"opening_week\",axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Meta Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(\"metascore\", axis=1, inplace=True) ## dropped the previous meta score code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.metascores.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.metascores.fillna(np.nanmean(df.metascores), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.metascores = df.metascores.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Munging Language, Country and year column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.language.replace('0', \"English\", inplace=True)\n",
    "df.country.replace('0', \"USA\", inplace=True)\n",
    "df.year = df.year.apply(lambda x : int(re.findall(r\"\\D(\\d{4})\\D\", x)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User_review and critic review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.user_review.replace(\",\", \"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.user_review = df.user_review.apply(lambda x: x.replace(\",\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.user_review = df.user_review.str.extract(r'(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.user_review.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.user_review.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.critic_review = df.critic_review.str.extract(r'(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.critic_review.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.critic_review.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### budget and gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.budget = df.budget.str.extract(r'(\\d+)')\n",
    "df.budget = df.budget.apply(lambda x: int(x))\n",
    "df.budget.replace(\"0\", None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.gross_1 = df.gross_1.str.extract(r'(\\d+)')\n",
    "df.gross_1 = df.gross_1.apply(lambda x: int(x))\n",
    "df.gross_1.replace(\"0\",None, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rotten Tomato scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rt_score = df.rt_score.str.extract(r'(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rt_score = [None if type(x) is float else int(x) for x in df.rt_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rt_avg_rating = [None if type(x) is float else x.split(\"/\")[0] for x in df.rt_avg_rating]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rt_avg_rating = [int(x) if x else None for x in df.rt_avg_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rt_audience_score = df.rt_audience_score.str.extract(r'(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rt_avg_aud_rating = [None if type(x) is float else x.split(\"/\")[0] for x in df.rt_avg_aud_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rt_user_rating = [i.replace(',',\"\") for i in df.rt_user_rating]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting Writers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = []\n",
    "for x in df.writer:\n",
    "    try:\n",
    "        a = x.split(\"(\")[0].strip()\n",
    "        a = a.strip(\",\")\n",
    "        a = a.replace(\" \", \"_\")\n",
    "    except:\n",
    "        a = None\n",
    "    writer.append(a)\n",
    "df.writer = writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_writer = []\n",
    "for i in df.writer:\n",
    "    if i not in unique_writer:\n",
    "        unique_writer.append(i)\n",
    "len(unique_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Dropping writer since there are too many unique values. \n",
    "df.drop(\"writer\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting Directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating a new column with only Directors name. \n",
    "director = []\n",
    "for x in df.director_actor:\n",
    "    try:\n",
    "        if \"Director:\" in x:\n",
    "            a = x\n",
    "    except:\n",
    "        a = None\n",
    "    director.append(a)\n",
    "df[\"director\"] = director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting rid of \n",
    "director_1 = []\n",
    "for i in df.director:\n",
    "    try:\n",
    "        a = i.split(\"|\")[0]\n",
    "        a = a.split(\":\")[1]\n",
    "        a = a.strip()\n",
    "        a = a.replace(\" \", \"_\")\n",
    "    except:\n",
    "        a = None\n",
    "    director_1.append(a)\n",
    "df[\"director\"] = director_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.director.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df[df.director.isnull()].director = \"Don Hertzfeldt\" ## was trying to manually import one missing value.\n",
    "## getting rid of that one missing value\n",
    "df.director.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_director = []\n",
    "for i in df.director:\n",
    "    if i not in u_director:\n",
    "        u_director.append(i)\n",
    "len(u_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Dropping \"director\" columns since there are too many unique values. \n",
    "df.drop(\"director\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting Actors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating a new column with only Directors name. \n",
    "actor = []\n",
    "for x in df.director_actor:\n",
    "    try:\n",
    "        if \"Stars:\" in x:\n",
    "            a = x\n",
    "    except:\n",
    "        a = None\n",
    "    actor.append(a)\n",
    "df[\"actors\"] = actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting rid of \n",
    "actor = []\n",
    "for i in df.actors:\n",
    "    try:\n",
    "        a = i.split(\"|\")[1]\n",
    "        a = a.split(\":\")[1]\n",
    "        a = a.strip(\"\\n\")\n",
    "        a = a.strip(\",\")\n",
    "        a = a.split(\",\")\n",
    "        #a = a.replace(\" \", \"_\")\n",
    "    except:\n",
    "        a = None\n",
    "    actor.append(a)\n",
    "df[\"actors\"] = actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.actors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = []\n",
    "for i in df.actors:\n",
    "    try:\n",
    "        a = []\n",
    "        for j in i:\n",
    "            c = j.strip()\n",
    "            c = c.replace(\" \",\"_\")\n",
    "            a.append(c)\n",
    "    except:\n",
    "        a = None\n",
    "    b.append(a)\n",
    "df.actors = b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.actors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping director_actor columns since its not needed anymore.\n",
    "df.drop(\"director_actor\", axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a unique list for directors, writers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Dropping the actors for now but will look into it in the future. \n",
    "df.drop(\"actors\",axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.certificate.replace(\"Not Rated\", \"Unrated\", inplace=True)\n",
    "df.certificate.replace(np.nan, \"Unrated\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.certificate.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "<a name=\"visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.heatmap(df.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.heatmap(df.corr()**2);\n",
    "plt.title(\"Correlation between features\", size = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.distplot(df.imdb_rating,bins = 50);\n",
    "plt.title(\"Distribution of imdb ratings among movies\", size = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the imdb_rating clearly shows how I have chosen two sets of movies. This could give me a result with better r scores. However, it is important to keep in mind that in the real work the distribution do not act similarly. Often you get data sets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.distplot(df.year,bins = 50);\n",
    "plt.title(\"Distribution of years among movies\", size = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the movies are pretty recent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "<a name =\"feature_engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"language\", \"country\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"certificate\"],dummy_na=True, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['label'] = df.imdb_rating.apply(lambda x : 1 if x > 7.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.label\n",
    "X = df.drop([\"title_id\", \"title\", \"imdb_rating\", \"label\" ],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "<a name=\"train_test_split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fancyimpute import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train= KNN(k=5).complete(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = KNN(k=5).complete(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing the mean for any nulls\n",
    "\"\"\"for i in numeric_columns:\n",
    "    X_train[i] = [X_train.i.mean() if x == np.nan else x for x in X_train[i]]\n",
    "    X_test[i] = [X_test.i.mean() if x == np.nan else x for x in X_test[i]]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = [\"runtime\", \"year\", \"votes\", \"user_review\", \"critic_review\", \"budget\", \"gross_1\", \"rt_score\", \"rt_avg_rating\", \"rt_audience_score\", \"rt_user_rating\", \"rt_avg_aud_rating\", \"rt_fresh\", \"rt_rotten\", \"metascores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train[scale] = scaler.fit_transform(X_train[scale])\n",
    "#X_test[scale] = scaler.fit_transform(X_test[scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test[scale] = scaler.fit_transform(X_test[scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "<a name=\"creating_models\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,precision_recall_curve\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding the best Max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# finding the best max depth for the DecisionTreeClassifier. \n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "for i in [1,2,3,4,5,6,7,None]:\n",
    "    print \"Max depth:{}\".format(i)\n",
    "    clf = DecisionTreeClassifier(max_depth=i)\n",
    "    print cross_val_score(clf, X_train, y_train, cv=cv, n_jobs =1).mean()\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'n_estimators': [10, 20, 30, 50, 100],\n",
    "    'max_features': [1,2,3,4,5,6,'auto'],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'class_weight': [\"balanced\",\"balanced_subsample\",None]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "dtc_ = DecisionTreeClassifier(max_depth=6)\n",
    "rf = RandomForestClassifier(dtc_)\n",
    "gs = GridSearchCV(rf, grid)\n",
    "\n",
    "model_rf_gs = gs.fit(X_train, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print gs.best_params_\n",
    "print gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Random Forest Model using the best param_ from GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features = gs.best_params_[\"max_features\"],\\\n",
    "                            n_estimators = gs.best_params_[\"n_estimators\"],\\\n",
    "                            criterion = gs.best_params_[\"criterion\"],\\\n",
    "                            class_weight = gs.best_params_[\"class_weight\"])\n",
    "model_rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predict y_train for X_train\n",
    "y_pred = model_rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predict y_test\n",
    "y_pred_test = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Metrics\n",
    "<a name=\"result_metrics\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing confision matrix\n",
    "pd.DataFrame(confusion_matrix(y_test,y_pred_test),\\\n",
    "            columns=[\"Predicted high\", \"Predicted low\"],\\\n",
    "            index=[\"is high\",\"is low\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print classification_report(y_train, y_pred, labels=model_rf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print classification report for y_test\n",
    "print classification_report(y_test, y_pred_test, labels=model_rf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Printing accuracy Score\n",
    "print accuracy_score(y_train, y_pred)\n",
    "print accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "<a name=\"feature_importance\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get features Gini scores\n",
    "feature_importances = pd.DataFrame(model_rf.feature_importances_, \n",
    "                                   index = X_train.columns, \n",
    "                                   columns=['importance'])\n",
    "\n",
    "feature_importances[feature_importances['importance']!=0].sort_values(by='importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC/AUC CURVE\n",
    "<a name=\"roc_auc_curve\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_score = model_rf_gs.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "FPR, TPR, _ = roc_curve(y_test, Y_score)\n",
    "ROC_AUC = auc(FPR, TPR)\n",
    "\"\"\"\n",
    "PREC, REC, _ = precision_recall_curve(y_test, Y_score)\n",
    "PR_AUC = auc(REC, PREC)\"\"\"\n",
    "\n",
    "# Plot of a ROC curve for class 1 (has_cancer)\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR, TPR, label='ROC curve (area = %0.2f)' % ROC_AUC, linewidth=4)\n",
    "#plt.plot(REC, PREC, label='PR curve (area = %0.2f)' % PR_AUC, linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive', fontsize=18)\n",
    "plt.ylabel('True Positive', fontsize=18)\n",
    "plt.title('Random Forest for imdb rating', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_score = model_rf_gs.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "PREC, REC, _ = precision_recall_curve(y_test, Y_score)\n",
    "PR_AUC = auc(REC, PREC)\n",
    "\n",
    "# Plot of a ROC curve for class 1 (has_cancer)\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(REC, PREC, label='PR curve (area = %0.2f)' % PR_AUC, linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall Rate', fontsize=18)\n",
    "plt.ylabel('Precision Rate', fontsize=18)\n",
    "plt.title('Random Forest for imdb rating', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping Up\n",
    "<a name=\"wrapping_up\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model seems to perform too well. One of the reasons could be the way I collected data. I hypothesis is that I was biased while collecting data. The way I web-scraped and collected my data points, there was a huge difference between the two types of data which is unlikely in the real world data problems. This is something to think about for the upcoming projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next..\n",
    "<a name=\"next\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe one of the reasons why my model was giving me really good results is because of the way I collected data from the beginning. While web scraping I basically collected two type of movies. First with imdb_rating over 8 and then imdb_rating below 5. Since there is a big gap in the rating, My model was able to predict too well. This is unlikely in the real world. Therefore, my next procedure would be to web scrape again but this time I should have more variety in the rating while scraping since it is my target variable. Also I would like to work with Actors, Director and Writers as a part of NLP for the next trial. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
