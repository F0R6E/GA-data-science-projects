{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "For this project, I will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "I am going to collect salary information on data science jobs in indeed. Then using the location, title, and summary of the job I will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, I will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second part, the focus is on using listings with salary information to build a model and predict high or low salaries and what features are predictive of that result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# \"%pdb\" you can use debugger for this function. \n",
    "# import pdb \n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Was inspired by Adam, he talked about this piece of code in class. \n",
    "# this function extracts location from \n",
    "def extract_location_from_result(result):\n",
    "    a = result.find(\"span\", class_ = \"location\") # Location\n",
    "    return None if a is None else a.text.strip()\n",
    "def salary_from_result(result):\n",
    "    a = result.find(\"nobr\")\n",
    "    return None if a is None else a.text.strip()\n",
    "def company_from_result(result):\n",
    "    a = result.find(\"span\", class_ = \"company\")\n",
    "    return None if a is None else a.text.strip()\n",
    "def jobtitle_from_result(result):\n",
    "    a = result.find(\"a\", attrs={'data-tn-element': \"jobTitle\"}) #Job title\n",
    "    return None if a is None else a.text.strip()\n",
    "def extract_summary_from_result(result):\n",
    "    a = result.find('span',class_='summary')\n",
    "    return None if a is None else a.text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 500\n",
    "\n",
    "# Creating 4 empty lists to store data from results. \n",
    "results = []\n",
    "job_title_lst = []\n",
    "location_lst = []\n",
    "company_lst = []\n",
    "salary_lst = []\n",
    "summary_lst = []\n",
    "\n",
    "# looks through the url to g\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Atlanta',\"Fort+Lee\",\"Boston\", \"Tampa\", \"Washington\",\"Seattle\", \"Pittsburgh\", \"Princeton\",\"Cincinnati\",\"Jersey+city\",\"Palm+beach\"]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_template.format(city, start)\n",
    "        r = requests.get(url)\n",
    "        page_html = r.content\n",
    "        soup = BeautifulSoup(page_html,\"lxml\")\n",
    "        result = soup.findAll(\"div\", class_ = \"result\")\n",
    "        results.append(result)\n",
    "        ## fix this \n",
    "        for i in results:\n",
    "            for a in i:\n",
    "                job_title_lst.append(jobtitle_from_result(a))\n",
    "                location_lst.append(extract_location_from_result(a))\n",
    "                company_lst.append(company_from_result(a))\n",
    "                salary_lst.append(salary_from_result(a))\n",
    "                summary_lst.append(extract_summary_from_result(a))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4204739\n",
      "4204739\n",
      "4204739\n",
      "4204739\n",
      "4204739\n"
     ]
    }
   ],
   "source": [
    "print (len(job_title_lst))\n",
    "print (len(location_lst))\n",
    "print (len(company_lst))\n",
    "print (len(salary_lst))\n",
    "print (len(summary_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a dataFrame from the four list created from the code above. \n",
    "df = pd.DataFrame({\"job_title\": job_title_lst, \"salary\": salary_lst, \"company\":company_lst, \"location\": location_lst, \"summary\":summary_lst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "df = df[[\"job_title\", \"salary\", \"location\", \"company\",\"summary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Big Data &amp; Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist - B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior NLP Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Elevano</td>\n",
       "      <td>Parsing of structured/unstructured data. Our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10017</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>We are currently looking for an exceptional Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Intelligence Analyst/Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Jersey City, NJ 07310 (Downtown area)</td>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>Effectively use Data Visualization techniques ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist with NLP Experience</td>\n",
       "      <td>None</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>EXL</td>\n",
       "      <td>Data Scientist with NLP Experience. EXL Analyt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_title salary  \\\n",
       "0         Data Scientist - Big Data & Analytics   None   \n",
       "1                     Senior NLP Data Scientist   None   \n",
       "2                           Lead Data Scientist   None   \n",
       "3  Business Intelligence Analyst/Data Scientist   None   \n",
       "4            Data Scientist with NLP Experience   None   \n",
       "\n",
       "                                location          company  \\\n",
       "0                     New York, NY 10154             KPMG   \n",
       "1                           New York, NY          Elevano   \n",
       "2                     New York, NY 10017            Aetna   \n",
       "3  Jersey City, NJ 07310 (Downtown area)  JP Morgan Chase   \n",
       "4                        Jersey City, NJ              EXL   \n",
       "\n",
       "                                             summary  \n",
       "0  KPMG is currently seeking a Data Scientist - B...  \n",
       "1  Parsing of structured/unstructured data. Our c...  \n",
       "2  We are currently looking for an exceptional Le...  \n",
       "3  Effectively use Data Visualization techniques ...  \n",
       "4  Data Scientist with NLP Experience. EXL Analyt...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "## Droping Duplicates\n",
    "df.drop_duplicates(inplace = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lessons for regular expression\n",
    "# \"^\" (carot) Stands before a text to match that text similar to startswith() from the string library. \n",
    "# \".\"(period) matches any characters. \n",
    "# \".+\"(period and plus) matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Big Data &amp; Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist - B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior NLP Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Elevano</td>\n",
       "      <td>Parsing of structured/unstructured data. Our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10017</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>We are currently looking for an exceptional Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Intelligence Analyst/Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Jersey City, NJ 07310 (Downtown area)</td>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>Effectively use Data Visualization techniques ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist with NLP Experience</td>\n",
       "      <td>None</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>EXL</td>\n",
       "      <td>Data Scientist with NLP Experience. EXL Analyt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_title salary  \\\n",
       "0         Data Scientist - Big Data & Analytics   None   \n",
       "1                     Senior NLP Data Scientist   None   \n",
       "2                           Lead Data Scientist   None   \n",
       "3  Business Intelligence Analyst/Data Scientist   None   \n",
       "4            Data Scientist with NLP Experience   None   \n",
       "\n",
       "                                location          company  \\\n",
       "0                     New York, NY 10154             KPMG   \n",
       "1                           New York, NY          Elevano   \n",
       "2                     New York, NY 10017            Aetna   \n",
       "3  Jersey City, NJ 07310 (Downtown area)  JP Morgan Chase   \n",
       "4                        Jersey City, NJ              EXL   \n",
       "\n",
       "                                             summary  \n",
       "0  KPMG is currently seeking a Data Scientist - B...  \n",
       "1  Parsing of structured/unstructured data. Our c...  \n",
       "2  We are currently looking for an exceptional Le...  \n",
       "3  Effectively use Data Visualization techniques ...  \n",
       "4  Data Scientist with NLP Experience. EXL Analyt...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splits column values based on \",\" and stores the first item. \n",
    "df[\"location\"] = df[\"location\"].apply(lambda x: None if x is None else x.split(\",\")[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lessons for regular expression\n",
    "# \"^\" (carot) Stands before a text to match that text similar to startswith() from the string library. \n",
    "# \".\"(period) matches any characters. \n",
    "# \".+\"(period and plus) matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# cleans job_title columns\\n# Del\\ndf[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"-\")[0].strip())\\ndf[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"/\")[0].strip())\\ndf[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"-\")[0].strip())\\ndf[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\",\")[0].strip())\\ndf[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"|\")[0].strip())\\ndf[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"(\")[0].strip())\\n\\n'"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# cleans job_title columns\n",
    "# Del\n",
    "df[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"-\")[0].strip())\n",
    "df[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"/\")[0].strip())\n",
    "df[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"-\")[0].strip())\n",
    "df[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\",\")[0].strip())\n",
    "df[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"|\")[0].strip())\n",
    "df[\"job_title\"] = df[\"job_title\"].apply(lambda x: None if x is None else x.split(\"(\")[0].strip())\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the type from unicode to text\n",
    "df[\"location\"] = df[\"location\"].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[\"job_title\"] = df[\"job_title\"].apply(lambda x : None if x is None else x.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"company\"] = df[\"company\"].apply(lambda x : None if x is None else x.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function is writen to clean salary column \n",
    "def fix_salary(n): \n",
    "    result = None\n",
    "    if n is None:\n",
    "        result = None\n",
    "    elif \"year\" in n:\n",
    "        a = re.findall('\\d\\S+', n)# \n",
    "        b = int(a[0].replace(\",\",\"\"))\n",
    "        try:\n",
    "            c = int(a[1].replace(\",\",\"\"))\n",
    "            avg = (b+c)/2\n",
    "            result = avg\n",
    "        except:\n",
    "            result = b\n",
    "    elif \"month\" in n:\n",
    "        a = re.findall('\\d\\S+', n)\n",
    "        b = int(a[0].replace(\",\",\"\"))\n",
    "        try:\n",
    "            c = int(a[1].replace(\",\",\"\"))\n",
    "            avg = (b+c)/2\n",
    "            result = avg*12\n",
    "        except:\n",
    "            result = b*12\n",
    "\n",
    "    elif \"hour\" in n:\n",
    "        a = re.findall('\\d\\S+', n)\n",
    "#         b = int(a[0].replace(\",\",\"\"))\n",
    "        b = float(a[0])\n",
    "        try:\n",
    "            c = float(a[1])\n",
    "#             c = int(a[1].replace(\",\",\"\"))\n",
    "            avg = (b+c)/2\n",
    "            result = avg*40*52\n",
    "        except:\n",
    "            result = b*40*52\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the fix_salary to clean salary data. \n",
    "df[\"salary\"] = df[\"salary\"].apply(fix_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3617"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = df.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>Research associate</td>\n",
       "      <td>41977.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>Research Foundation of The City University of ...</td>\n",
       "      <td>Assists scientists, students, and other techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415</td>\n",
       "      <td>Statistician, Level I</td>\n",
       "      <td>52903.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>POLICE DEPARTMENT</td>\n",
       "      <td>Selected candidate will be responsible for pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>668</td>\n",
       "      <td>Data Analyst, Bureau of Immunization</td>\n",
       "      <td>65977.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>DEPT OF HEALTH/MENTAL HYGIENE</td>\n",
       "      <td>Review program data, assuring data quality and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>817</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Major insurance company seeks an experienced S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985</td>\n",
       "      <td>Data Analyst/Modeler</td>\n",
       "      <td>75557.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>DEPARTMENT OF FINANCE</td>\n",
       "      <td>Strong programming, data analysis, statistical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                             job_title    salary   location  \\\n",
       "0     85                    Research associate   41977.0   New York   \n",
       "1    415                 Statistician, Level I   52903.0   New York   \n",
       "2    668  Data Analyst, Bureau of Immunization   65977.0   New York   \n",
       "3    817                 Senior Data Scientist  160000.0   New York   \n",
       "4    985                  Data Analyst/Modeler   75557.0  Manhattan   \n",
       "\n",
       "                                             company  \\\n",
       "0  Research Foundation of The City University of ...   \n",
       "1                                  POLICE DEPARTMENT   \n",
       "2                      DEPT OF HEALTH/MENTAL HYGIENE   \n",
       "3                                Analytic Recruiting   \n",
       "4                              DEPARTMENT OF FINANCE   \n",
       "\n",
       "                                             summary  \n",
       "0  Assists scientists, students, and other techni...  \n",
       "1  Selected candidate will be responsible for pro...  \n",
       "2  Review program data, assuring data quality and...  \n",
       "3  Major insurance company seeks an experienced S...  \n",
       "4  Strong programming, data analysis, statistical...  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_df[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research associate</td>\n",
       "      <td>41977.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>Research Foundation of The City University of ...</td>\n",
       "      <td>Assists scientists, students, and other techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statistician, Level I</td>\n",
       "      <td>52903.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>POLICE DEPARTMENT</td>\n",
       "      <td>Selected candidate will be responsible for pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst, Bureau of Immunization</td>\n",
       "      <td>65977.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>DEPT OF HEALTH/MENTAL HYGIENE</td>\n",
       "      <td>Review program data, assuring data quality and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Major insurance company seeks an experienced S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst/Modeler</td>\n",
       "      <td>75557.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>DEPARTMENT OF FINANCE</td>\n",
       "      <td>Strong programming, data analysis, statistical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              job_title    salary   location  \\\n",
       "0                    Research associate   41977.0   New York   \n",
       "1                 Statistician, Level I   52903.0   New York   \n",
       "2  Data Analyst, Bureau of Immunization   65977.0   New York   \n",
       "3                 Senior Data Scientist  160000.0   New York   \n",
       "4                  Data Analyst/Modeler   75557.0  Manhattan   \n",
       "\n",
       "                                             company  \\\n",
       "0  Research Foundation of The City University of ...   \n",
       "1                                  POLICE DEPARTMENT   \n",
       "2                      DEPT OF HEALTH/MENTAL HYGIENE   \n",
       "3                                Analytic Recruiting   \n",
       "4                              DEPARTMENT OF FINANCE   \n",
       "\n",
       "                                             summary  \n",
       "0  Assists scientists, students, and other techni...  \n",
       "1  Selected candidate will be responsible for pro...  \n",
       "2  Review program data, assuring data quality and...  \n",
       "3  Major insurance company seeks an experienced S...  \n",
       "4  Strong programming, data analysis, statistical...  "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"salary_category\"] = train_df[\"salary\"].apply(lambda x : \"high\" if x > np.mean(train_df[\"salary\"]) else \"low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_category</th>\n",
       "      <th>location_Arlington</th>\n",
       "      <th>location_Atlanta</th>\n",
       "      <th>location_Austin</th>\n",
       "      <th>location_Bellevue</th>\n",
       "      <th>location_Berkeley</th>\n",
       "      <th>location_Boston</th>\n",
       "      <th>location_Bridgewater</th>\n",
       "      <th>location_Brooklyn</th>\n",
       "      <th>...</th>\n",
       "      <th>services</th>\n",
       "      <th>smith</th>\n",
       "      <th>solutions</th>\n",
       "      <th>south</th>\n",
       "      <th>state</th>\n",
       "      <th>texas</th>\n",
       "      <th>university</th>\n",
       "      <th>washington</th>\n",
       "      <th>water</th>\n",
       "      <th>workbridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41977.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52903.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65977.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75557.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     salary salary_category  location_Arlington  location_Atlanta  \\\n",
       "0   41977.0             low                   0                 0   \n",
       "1   52903.0             low                   0                 0   \n",
       "2   65977.0             low                   0                 0   \n",
       "3  160000.0            high                   0                 0   \n",
       "4   75557.0             low                   0                 0   \n",
       "\n",
       "   location_Austin  location_Bellevue  location_Berkeley  location_Boston  \\\n",
       "0                0                  0                  0                0   \n",
       "1                0                  0                  0                0   \n",
       "2                0                  0                  0                0   \n",
       "3                0                  0                  0                0   \n",
       "4                0                  0                  0                0   \n",
       "\n",
       "   location_Bridgewater  location_Brooklyn     ...      services  smith  \\\n",
       "0                     0                  0     ...             0      0   \n",
       "1                     0                  0     ...             0      0   \n",
       "2                     0                  0     ...             0      0   \n",
       "3                     0                  0     ...             0      0   \n",
       "4                     0                  0     ...             0      0   \n",
       "\n",
       "   solutions  south  state  texas  university  washington  water  workbridge  \n",
       "0          0      0      0      0           1           0      0           0  \n",
       "1          0      0      0      0           0           0      0           0  \n",
       "2          0      0      0      0           0           0      0           0  \n",
       "3          0      0      0      0           0           0      0           0  \n",
       "4          0      0      0      0           0           0      0           0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#X = pd.concat(pd.DataFrame(train_df.ix[:,\"job_title\"]), pd.DataFrame(train_df.ix[:,\"location\":]),ignore_index=True)\\ncolumns_list = [\\'company\\',\\'job_title\\',\\'summary\\',\\'location\\']\\nX = train_df[columns_list]'"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#X = pd.concat(pd.DataFrame(train_df.ix[:,\"job_title\"]), pd.DataFrame(train_df.ix[:,\"location\":]),ignore_index=True)\n",
    "columns_list = ['company','job_title','summary','location']\n",
    "X = train_df[columns_list]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Text feature for job_title and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build text features for job title and summary\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(\n",
    "    binary=True,  # Create binary features\n",
    "    stop_words ='english', # Ignore common words \n",
    "    max_features= 40 \n",
    ")\n",
    "\n",
    "jwords_df = v.fit_transform(train_df[\"job_title\"]).todense()\n",
    "jwords_df = pd.DataFrame(jwords_df, columns=v.get_feature_names())\n",
    "\n",
    "swords_df = v.fit_transform(train_df['summary']).todense()\n",
    "swords_df = pd.DataFrame(swords_df, columns=v.get_feature_names())\n",
    "\n",
    "com_words_df = v.fit_transform(train_df['company']).todense()\n",
    "com_words_df = pd.DataFrame(com_words_df, columns=v.get_feature_names())\n",
    "\n",
    "loc_words_df = v.fit_transform(train_df['company']).todense()\n",
    "loc_words_df = pd.DataFrame(loc_words_df, columns=v.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 40)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jwords_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 40)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_words_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorizing the salary column so that we can use logistic regression model.\n",
    "#df[\"salary_position\"] = df[\"salary\"].apply(lambda x: None if x is None elif 'high' if x > df['salary'].mean() else 'low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"import patsy\n",
    "location_df = patsy.dmatrix('~ C(location)',train_df)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My model starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in swords_df.columns:\n",
    "    if i in jwords_df.columns:\n",
    "        del jwords_df[i]\n",
    "    if i in com_words_df.columns:\n",
    "        del com_words_df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in jwords_df.columns:\n",
    "    if i in com_words_df.columns:\n",
    "        del com_words_df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, columns=['location'], drop_first=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.join(jwords_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.join(swords_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.join(com_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['company','job_title','summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_category</th>\n",
       "      <th>location_Arlington</th>\n",
       "      <th>location_Atlanta</th>\n",
       "      <th>location_Austin</th>\n",
       "      <th>location_Bellevue</th>\n",
       "      <th>location_Berkeley</th>\n",
       "      <th>location_Boston</th>\n",
       "      <th>location_Bridgewater</th>\n",
       "      <th>location_Brooklyn</th>\n",
       "      <th>...</th>\n",
       "      <th>services</th>\n",
       "      <th>smith</th>\n",
       "      <th>solutions</th>\n",
       "      <th>south</th>\n",
       "      <th>state</th>\n",
       "      <th>texas</th>\n",
       "      <th>university</th>\n",
       "      <th>washington</th>\n",
       "      <th>water</th>\n",
       "      <th>workbridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41977.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52903.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65977.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75557.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     salary salary_category  location_Arlington  location_Atlanta  \\\n",
       "0   41977.0             low                   0                 0   \n",
       "1   52903.0             low                   0                 0   \n",
       "2   65977.0             low                   0                 0   \n",
       "3  160000.0            high                   0                 0   \n",
       "4   75557.0             low                   0                 0   \n",
       "\n",
       "   location_Austin  location_Bellevue  location_Berkeley  location_Boston  \\\n",
       "0                0                  0                  0                0   \n",
       "1                0                  0                  0                0   \n",
       "2                0                  0                  0                0   \n",
       "3                0                  0                  0                0   \n",
       "4                0                  0                  0                0   \n",
       "\n",
       "   location_Bridgewater  location_Brooklyn     ...      services  smith  \\\n",
       "0                     0                  0     ...             0      0   \n",
       "1                     0                  0     ...             0      0   \n",
       "2                     0                  0     ...             0      0   \n",
       "3                     0                  0     ...             0      0   \n",
       "4                     0                  0     ...             0      0   \n",
       "\n",
       "   solutions  south  state  texas  university  washington  water  workbridge  \n",
       "0          0      0      0      0           1           0      0           0  \n",
       "1          0      0      0      0           0           0      0           0  \n",
       "2          0      0      0      0           0           0      0           0  \n",
       "3          0      0      0      0           0           0      0           0  \n",
       "4          0      0      0      0           0           0      0           0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train = train_df.ix[:,\"salary_category\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = new_train[\"salary_category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = new_train.ix[:,\"location_Arlington\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 158)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 159)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# of course my trainning and test will be different.\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(X, y, test_size=0.33, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4 5 6 8\n"
     ]
    }
   ],
   "source": [
    "calories = map(int, raw_input().strip().split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 5, 6, 8]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 6, 5, 4, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(calories, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's fit a standard logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make our predictions\n",
    "lr_ypred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      high  low\n",
       "high    26   10\n",
       "low      6   37"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our misclassifications with a confusion matrix\n",
    "lr_cm = confusion_matrix(y_test,lr_ypred, labels=lr.classes_)\n",
    "lr_cm = pd.DataFrame(lr_cm, columns=lr.classes_, index=lr.classes_)\n",
    "lr_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.81      0.72      0.76        36\n",
      "        low       0.79      0.86      0.82        43\n",
      "\n",
      "avg / total       0.80      0.80      0.80        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check our precision, recall, and f1\n",
    "print classification_report(y_test, lr_ypred, labels=lr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79746835443\n"
     ]
    }
   ],
   "source": [
    "# check accuracy score\n",
    "print accuracy_score(y_test, lr_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.725     ,  0.65      ,  0.73417722])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the CV Score\n",
    "cvs1 = cross_val_score(lr, X, y, cv=3)\n",
    "cvs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized regression - LASSO (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.36336419e-01,   7.63663581e-01],\n",
       "       [  9.75585254e-01,   2.44147461e-02],\n",
       "       [  2.08354880e-08,   9.99999979e-01],\n",
       "       [  2.41239685e-02,   9.75876031e-01],\n",
       "       [  4.11490248e-02,   9.58850975e-01],\n",
       "       [  8.76141057e-01,   1.23858943e-01],\n",
       "       [  5.60569728e-02,   9.43943027e-01],\n",
       "       [  1.00020442e-01,   8.99979558e-01],\n",
       "       [  9.99082813e-01,   9.17187423e-04],\n",
       "       [  7.71759934e-02,   9.22824007e-01],\n",
       "       [  9.91528127e-01,   8.47187319e-03],\n",
       "       [  9.07207292e-01,   9.27927083e-02],\n",
       "       [  3.01983462e-04,   9.99698017e-01],\n",
       "       [  2.66657173e-04,   9.99733343e-01],\n",
       "       [  6.47241998e-03,   9.93527580e-01],\n",
       "       [  9.76246855e-01,   2.37531454e-02],\n",
       "       [  6.87993529e-01,   3.12006471e-01],\n",
       "       [  2.41625788e-03,   9.97583742e-01],\n",
       "       [  2.45955675e-02,   9.75404432e-01],\n",
       "       [  5.50180440e-01,   4.49819560e-01],\n",
       "       [  3.30168862e-01,   6.69831138e-01],\n",
       "       [  3.70473277e-01,   6.29526723e-01],\n",
       "       [  9.98583371e-01,   1.41662868e-03],\n",
       "       [  5.89522985e-04,   9.99410477e-01],\n",
       "       [  9.99290741e-01,   7.09259038e-04],\n",
       "       [  9.13924259e-03,   9.90860757e-01],\n",
       "       [  7.55191194e-02,   9.24480881e-01],\n",
       "       [  9.97124916e-01,   2.87508376e-03],\n",
       "       [  4.83867641e-01,   5.16132359e-01],\n",
       "       [  5.98395353e-01,   4.01604647e-01],\n",
       "       [  9.86524330e-01,   1.34756702e-02],\n",
       "       [  1.98245862e-02,   9.80175414e-01],\n",
       "       [  3.22091275e-03,   9.96779087e-01],\n",
       "       [  9.90734815e-01,   9.26518476e-03],\n",
       "       [  1.49356737e-01,   8.50643263e-01],\n",
       "       [  6.57947050e-01,   3.42052950e-01],\n",
       "       [  2.70238596e-04,   9.99729761e-01],\n",
       "       [  1.45895943e-04,   9.99854104e-01],\n",
       "       [  9.32945908e-01,   6.70540925e-02],\n",
       "       [  9.94294690e-01,   5.70530962e-03],\n",
       "       [  3.21095122e-01,   6.78904878e-01],\n",
       "       [  9.99413182e-01,   5.86818237e-04],\n",
       "       [  9.42668697e-01,   5.73313027e-02],\n",
       "       [  3.43202884e-06,   9.99996568e-01],\n",
       "       [  9.99852475e-01,   1.47524801e-04],\n",
       "       [  9.14000087e-01,   8.59999128e-02],\n",
       "       [  3.58094171e-03,   9.96419058e-01],\n",
       "       [  1.18459997e-09,   9.99999999e-01],\n",
       "       [  4.25460487e-02,   9.57453951e-01],\n",
       "       [  1.23995910e-01,   8.76004090e-01],\n",
       "       [  5.02258240e-01,   4.97741760e-01],\n",
       "       [  9.70630900e-01,   2.93691004e-02],\n",
       "       [  5.05933555e-01,   4.94066445e-01],\n",
       "       [  1.42737656e-05,   9.99985726e-01],\n",
       "       [  8.44382577e-02,   9.15561742e-01],\n",
       "       [  5.33841033e-02,   9.46615897e-01],\n",
       "       [  9.99427097e-01,   5.72903468e-04],\n",
       "       [  7.90231443e-03,   9.92097686e-01],\n",
       "       [  9.14417746e-01,   8.55822541e-02],\n",
       "       [  6.43957515e-01,   3.56042485e-01],\n",
       "       [  2.48965349e-03,   9.97510347e-01],\n",
       "       [  2.50554391e-01,   7.49445609e-01],\n",
       "       [  9.13701069e-01,   8.62989310e-02],\n",
       "       [  1.02493914e-01,   8.97506086e-01],\n",
       "       [  3.15454177e-03,   9.96845458e-01],\n",
       "       [  5.40922937e-05,   9.99945908e-01],\n",
       "       [  8.60904279e-03,   9.91390957e-01],\n",
       "       [  8.05555506e-01,   1.94444494e-01],\n",
       "       [  8.04416097e-01,   1.95583903e-01],\n",
       "       [  2.04587365e-03,   9.97954126e-01],\n",
       "       [  2.66734066e-03,   9.97332659e-01],\n",
       "       [  1.50492379e-01,   8.49507621e-01],\n",
       "       [  6.29976352e-01,   3.70023648e-01],\n",
       "       [  3.02028680e-01,   6.97971320e-01],\n",
       "       [  9.99960584e-01,   3.94161586e-05],\n",
       "       [  9.31047306e-01,   6.89526936e-02],\n",
       "       [  4.81498788e-03,   9.95185012e-01],\n",
       "       [  7.30725402e-03,   9.92692746e-01],\n",
       "       [  4.68894548e-01,   5.31105452e-01]])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now use a penalized regression - we'll use LASSO (L1)\n",
    "lr_l1 = LogisticRegression(C=10, penalty='l1')\n",
    "lr_l1_model = lr_l1.fit(X_train, y_train)\n",
    "lr_l1_ypred = lr_l1_model.predict(X_test)\n",
    "lr_l1_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      high  low\n",
      "high    21   15\n",
      "low     12   31 \n",
      "\n",
      "      high  low\n",
      "high    26   10\n",
      "low      6   37\n"
     ]
    }
   ],
   "source": [
    "# Get the confusion matrix\n",
    "lr_l1_cm = confusion_matrix(y_test, lr_l1_ypred, labels=lr_l1.classes_)\n",
    "lr_l1_cm = pd.DataFrame(lr_l1_cm, columns=lr_l1.classes_,\\\n",
    "                        index=lr_l1.classes_)\n",
    "print lr_l1_cm, \"\\n\"\n",
    "\n",
    "print lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.64      0.58      0.61        36\n",
      "        low       0.67      0.72      0.70        43\n",
      "\n",
      "avg / total       0.66      0.66      0.66        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the classification report\n",
    "print classification_report(y_test, lr_l1_ypred, labels=lr_l1.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658227848101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check accuracy score\n",
    "print accuracy_score(y_test, lr_l1_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65675105485232066"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get mean cross val score\n",
    "cvs2 = cross_val_score(lr_l1, X, y, cv=3)\n",
    "np.mean(cvs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656751054852\n",
      "0.70305907173\n"
     ]
    }
   ],
   "source": [
    "# compare between the two \n",
    "print cvs2.mean()\n",
    "\n",
    "print cvs1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the classification report for our best model\n",
    "print classification_report(y_test, logreg_cv.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=15, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 0.15, 0.25, 0.275, 0.33, 0.5, 0.66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=False)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear')\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = GridSearchCV(logreg, {'penalty': penalties, 'C': C_vals},\\\n",
    "                  verbose=False, cv=15)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 0.15}\n",
      "0.694560669456\n"
     ]
    }
   ],
   "source": [
    "# finding the best parameters\n",
    "print gs.best_params_\n",
    "print gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this parameter to fit, predict, and print a classification_report for our X and Y\n",
    "logreg = LogisticRegression(C=gs.best_params_['C'],\\\n",
    "                            penalty=gs.best_params_['penalty'])\n",
    "cv_model = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pred = cv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(y_test, cv_pred, labels=logreg.classes_)\n",
    "cm3 = pd.DataFrame(cm3, columns=logreg.classes_, index=logreg.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      high  low\n",
      "high    24   12\n",
      "low      6   37\n"
     ]
    }
   ],
   "source": [
    "print cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression confusion Matrix: \n",
      "      high  low\n",
      "high    26   10\n",
      "low      6   37\n",
      "L1 confusion Matrix: \n",
      "      high  low\n",
      "high    21   15\n",
      "low     12   31\n",
      "confusion Matrix using grid search results: \n",
      "      high  low\n",
      "high    24   12\n",
      "low      6   37\n"
     ]
    }
   ],
   "source": [
    "print \"Logistic Regression confusion Matrix: \\n\", lr_cm\n",
    "print \"L1 confusion Matrix: \\n\",lr_l1_cm\n",
    "print \"confusion Matrix using grid search results: \\n\", cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.80      0.67      0.73        36\n",
      "        low       0.76      0.86      0.80        43\n",
      "\n",
      "avg / total       0.78      0.77      0.77        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, cv_pred,\\\n",
    "                            labels=logreg.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772151898734\n"
     ]
    }
   ],
   "source": [
    "# check accuracy score\n",
    "print accuracy_score(y_test, cv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(zip(X_train.columns, abs(cv_model.coef_[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location_Arlington</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location_Atlanta</td>\n",
       "      <td>0.158689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location_Austin</td>\n",
       "      <td>0.103552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_Bellevue</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>location_Berkeley</td>\n",
       "      <td>0.054088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>location_Boston</td>\n",
       "      <td>0.121711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>location_Bridgewater</td>\n",
       "      <td>0.229213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>location_Brooklyn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>location_Cambridge</td>\n",
       "      <td>0.110307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>location_Chantilly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>location_Chicago</td>\n",
       "      <td>0.011060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>location_Cincinnati</td>\n",
       "      <td>0.057384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>location_College Park</td>\n",
       "      <td>0.056525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>location_Dayton</td>\n",
       "      <td>0.061146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>location_Deerfield</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>location_East Bay</td>\n",
       "      <td>0.037139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>location_East Brunswick</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>location_East Hanover</td>\n",
       "      <td>0.054634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>location_Edgely</td>\n",
       "      <td>0.068494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>location_Emeryville</td>\n",
       "      <td>0.066176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>location_Evanston</td>\n",
       "      <td>0.074788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>location_Fort Meade</td>\n",
       "      <td>0.020063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>location_Hopewell</td>\n",
       "      <td>0.096837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>location_Jersey City</td>\n",
       "      <td>0.056762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>location_Jupiter</td>\n",
       "      <td>0.039350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>location_Lemont</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>location_Manhattan</td>\n",
       "      <td>0.203247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location_Matawan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>location_Md City</td>\n",
       "      <td>0.030109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>location_Montvale</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>control</td>\n",
       "      <td>0.113772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>county</td>\n",
       "      <td>0.172644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>department</td>\n",
       "      <td>0.265326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>dept</td>\n",
       "      <td>0.319813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>disease</td>\n",
       "      <td>0.113772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>district</td>\n",
       "      <td>0.176661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>enterprise</td>\n",
       "      <td>0.103464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>florida</td>\n",
       "      <td>0.204502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>group</td>\n",
       "      <td>0.085378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>hanley</td>\n",
       "      <td>0.020251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>huxley</td>\n",
       "      <td>0.065688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>international</td>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>jobspring</td>\n",
       "      <td>0.202166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>llc</td>\n",
       "      <td>0.137644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>partners</td>\n",
       "      <td>0.243856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>prevention</td>\n",
       "      <td>0.113772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>recruiting</td>\n",
       "      <td>0.105815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>recruitment</td>\n",
       "      <td>0.104034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>security</td>\n",
       "      <td>0.020063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>select</td>\n",
       "      <td>0.103464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>services</td>\n",
       "      <td>0.253600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>smith</td>\n",
       "      <td>0.020251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>solutions</td>\n",
       "      <td>0.084142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>south</td>\n",
       "      <td>0.168380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>state</td>\n",
       "      <td>0.110485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>texas</td>\n",
       "      <td>0.026594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>university</td>\n",
       "      <td>0.420373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>washington</td>\n",
       "      <td>0.143627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>water</td>\n",
       "      <td>0.201904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>workbridge</td>\n",
       "      <td>0.139337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1\n",
       "0         location_Arlington  0.000000\n",
       "1           location_Atlanta  0.158689\n",
       "2            location_Austin  0.103552\n",
       "3          location_Bellevue  0.001965\n",
       "4          location_Berkeley  0.054088\n",
       "5            location_Boston  0.121711\n",
       "6       location_Bridgewater  0.229213\n",
       "7          location_Brooklyn  0.000000\n",
       "8         location_Cambridge  0.110307\n",
       "9         location_Chantilly  0.000000\n",
       "10          location_Chicago  0.011060\n",
       "11       location_Cincinnati  0.057384\n",
       "12     location_College Park  0.056525\n",
       "13           location_Dayton  0.061146\n",
       "14        location_Deerfield  0.000000\n",
       "15         location_East Bay  0.037139\n",
       "16   location_East Brunswick  0.000000\n",
       "17     location_East Hanover  0.054634\n",
       "18           location_Edgely  0.068494\n",
       "19       location_Emeryville  0.066176\n",
       "20         location_Evanston  0.074788\n",
       "21       location_Fort Meade  0.020063\n",
       "22         location_Hopewell  0.096837\n",
       "23      location_Jersey City  0.056762\n",
       "24          location_Jupiter  0.039350\n",
       "25           location_Lemont  0.000000\n",
       "26        location_Manhattan  0.203247\n",
       "27          location_Matawan  0.000000\n",
       "28          location_Md City  0.030109\n",
       "29         location_Montvale  0.000000\n",
       "..                       ...       ...\n",
       "128                  control  0.113772\n",
       "129                   county  0.172644\n",
       "130               department  0.265326\n",
       "131                     dept  0.319813\n",
       "132                  disease  0.113772\n",
       "133                 district  0.176661\n",
       "134               enterprise  0.103464\n",
       "135                  florida  0.204502\n",
       "136                    group  0.085378\n",
       "137                   hanley  0.020251\n",
       "138                   huxley  0.065688\n",
       "139            international  0.002113\n",
       "140                jobspring  0.202166\n",
       "141                      llc  0.137644\n",
       "142                 partners  0.243856\n",
       "143               prevention  0.113772\n",
       "144               recruiting  0.105815\n",
       "145              recruitment  0.104034\n",
       "146                 security  0.020063\n",
       "147                   select  0.103464\n",
       "148                 services  0.253600\n",
       "149                    smith  0.020251\n",
       "150                solutions  0.084142\n",
       "151                    south  0.168380\n",
       "152                    state  0.110485\n",
       "153                    texas  0.026594\n",
       "154               university  0.420373\n",
       "155               washington  0.143627\n",
       "156                    water  0.201904\n",
       "157               workbridge  0.139337\n",
       "\n",
       "[158 rows x 2 columns]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masumrumi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>analysis</td>\n",
       "      <td>0.437172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>big</td>\n",
       "      <td>0.424814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>university</td>\n",
       "      <td>0.420373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>associate</td>\n",
       "      <td>0.418473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>research</td>\n",
       "      <td>0.401182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>engineer</td>\n",
       "      <td>0.369078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>new</td>\n",
       "      <td>0.359925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>dept</td>\n",
       "      <td>0.319813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sr</td>\n",
       "      <td>0.285695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>director</td>\n",
       "      <td>0.283389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>department</td>\n",
       "      <td>0.265326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>senior</td>\n",
       "      <td>0.254989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.254434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>services</td>\n",
       "      <td>0.253600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>0.250014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>partners</td>\n",
       "      <td>0.243856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>scientists</td>\n",
       "      <td>0.229764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>location_Bridgewater</td>\n",
       "      <td>0.229213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>looking</td>\n",
       "      <td>0.224519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>manager</td>\n",
       "      <td>0.214615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>florida</td>\n",
       "      <td>0.204502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>location_Manhattan</td>\n",
       "      <td>0.203247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>jobspring</td>\n",
       "      <td>0.202166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>water</td>\n",
       "      <td>0.201904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>team</td>\n",
       "      <td>0.200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>information</td>\n",
       "      <td>0.196741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>statistical</td>\n",
       "      <td>0.193163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>associates</td>\n",
       "      <td>0.186519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>developer</td>\n",
       "      <td>0.186143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>results</td>\n",
       "      <td>0.183343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>modeling</td>\n",
       "      <td>0.023618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>statistician</td>\n",
       "      <td>0.020995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>hanley</td>\n",
       "      <td>0.020251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>smith</td>\n",
       "      <td>0.020251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>security</td>\n",
       "      <td>0.020063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>agency</td>\n",
       "      <td>0.020063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>location_Fort Meade</td>\n",
       "      <td>0.020063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>develop</td>\n",
       "      <td>0.019630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>software</td>\n",
       "      <td>0.018246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>location_Chicago</td>\n",
       "      <td>0.011060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>python</td>\n",
       "      <td>0.009272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>safety</td>\n",
       "      <td>0.007383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>business</td>\n",
       "      <td>0.003361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>austin</td>\n",
       "      <td>0.002834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>international</td>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_Bellevue</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>using</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>location_Brooklyn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>assistant</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>location_Chantilly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>location_Deerfield</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>location_East Brunswick</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>location_Lemont</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location_Matawan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>location_Montvale</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>location_Redmond</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>location_San Mateo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>location_Tampa</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>location_Tampa Bay</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location_Arlington</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1\n",
       "81                  analysis  0.437172\n",
       "85                       big  0.424814\n",
       "154               university  0.420373\n",
       "55                 associate  0.418473\n",
       "105                 research  0.401182\n",
       "59                  engineer  0.369078\n",
       "102                      new  0.359925\n",
       "131                     dept  0.319813\n",
       "77                        sr  0.285695\n",
       "58                  director  0.283389\n",
       "130               department  0.265326\n",
       "111                   senior  0.254989\n",
       "90                experience  0.254434\n",
       "148                 services  0.253600\n",
       "74              quantitative  0.250014\n",
       "142                 partners  0.243856\n",
       "109               scientists  0.229764\n",
       "6       location_Bridgewater  0.229213\n",
       "97                   looking  0.224519\n",
       "69                   manager  0.214615\n",
       "135                  florida  0.204502\n",
       "26        location_Manhattan  0.203247\n",
       "140                jobspring  0.202166\n",
       "156                    water  0.201904\n",
       "115                     team  0.200209\n",
       "92               information  0.196741\n",
       "113              statistical  0.193163\n",
       "122               associates  0.186519\n",
       "57                 developer  0.186143\n",
       "106                  results  0.183343\n",
       "..                       ...       ...\n",
       "101                 modeling  0.023618\n",
       "78              statistician  0.020995\n",
       "137                   hanley  0.020251\n",
       "149                    smith  0.020251\n",
       "146                 security  0.020063\n",
       "121                   agency  0.020063\n",
       "21       location_Fort Meade  0.020063\n",
       "87                   develop  0.019630\n",
       "112                 software  0.018246\n",
       "10          location_Chicago  0.011060\n",
       "73                    python  0.009272\n",
       "75                    safety  0.007383\n",
       "56                  business  0.003361\n",
       "123                   austin  0.002834\n",
       "139            international  0.002113\n",
       "3          location_Bellevue  0.001965\n",
       "117                    using  0.000145\n",
       "7          location_Brooklyn  0.000000\n",
       "54                 assistant  0.000000\n",
       "9         location_Chantilly  0.000000\n",
       "14        location_Deerfield  0.000000\n",
       "16   location_East Brunswick  0.000000\n",
       "25           location_Lemont  0.000000\n",
       "27          location_Matawan  0.000000\n",
       "29         location_Montvale  0.000000\n",
       "37          location_Redmond  0.000000\n",
       "42        location_San Mateo  0.000000\n",
       "47            location_Tampa  0.000000\n",
       "48        location_Tampa Bay  0.000000\n",
       "0         location_Arlington  0.000000\n",
       "\n",
       "[158 rows x 2 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort([1], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
